{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means clustering from \"Scratch\"\n",
    "\n",
    "The k-means clustering algorithm is one of the most basic forms of unsupervised\n",
    "machine learning, and is foundational to a number of other ML methods.\n",
    "\n",
    "In this notebook I'll go over the general algorithms, some of the mathematical\n",
    "intuitions for the methods, and implement a simple \"from scratch\" function in\n",
    "python using minimal packages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $k$-means clustering algorithm\n",
    "\n",
    "The most common practical implementation of $k$-means clustering is an iterative method called Lloyd's algorithm, which is both simple and quick. It does, however, have some drawbacks.\n",
    "\n",
    "The algorithm is really very straightforward:  \n",
    "1. Initialize either with $k$ randomly selected points in the $n$-dimensional\n",
    "   feature space or $k$ randomly selected data points\n",
    "2. Assign all data points to the nearest of the $k$ selected points/centers\n",
    "3. Find the centroid of each $k$ assigned cluster\n",
    "\n",
    "Repeat steps 2 and 3 until the assignments and/or centroids stop changing.\n",
    "\n",
    "The goal is simple -- find an assignment for all points such that, for each\n",
    "cluster, the within-cluster data points are closer to the group's centroid than\n",
    "they are to any other group's center.\n",
    "\n",
    "So, we basically have five tasks to code:\n",
    "1. Initialize\n",
    "2. Distance\n",
    "3. Assignment\n",
    "4. Find centers\n",
    "5. Stopping criteria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The only package we'll be using is `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize $k$ centers\n",
    "\n",
    "For this example, we'll select $k$ of our data points at random to facilitate\n",
    "convergence. Alternatively, one could assign $k$ arbitrary points somewhere\n",
    "within the overall range of the data.\n",
    "\n",
    "To help randomize the selection, we'll make our random selection with\n",
    "[`numpy.random.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html)\n",
    "from a \"shuffled\" data set using\n",
    "[`numpy.random.shuffle`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diy_kmeans_initialize(dat, k_clust):\n",
    "\n",
    "    # Copy the source data array\n",
    "\n",
    "    dat_shuffled = dat.copy()\n",
    "\n",
    "    # Shuffle the copy\n",
    "\n",
    "    np.random.default_rng().shuffle(dat_shuffled, axis=0)\n",
    "\n",
    "    # Choose k random points from the shuffled matrix\n",
    "\n",
    "    k_centers = dat_shuffled[np.random.choice(\n",
    "        dat_shuffled.shape[0], k_clust, replace=False), :]\n",
    "\n",
    "    return k_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance\n",
    "\n",
    "Find the squared Euclidean distance between each data point and each of the $k$\n",
    "centers. We'll use `numpy.linalg.norm` to calculate the equivalent square of the\n",
    "Froebenius or $\\ell^2$ matrix norm to generate a matrix $S$ of the squared\n",
    "distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diy_kmeans_distance(dat, centers):\n",
    "\n",
    "    S = np.empty((dat.shape[0], centers.shape[0]))\n",
    "\n",
    "    # Find L2 norm (Euclidean distance) from each center\n",
    "\n",
    "    for k in range(centers.shape[0]):\n",
    "        S[:, k] = np.linalg.norm(dat - centers[k, :], axis=1)\n",
    "\n",
    "    # Return the squared distances\n",
    "\n",
    "    return np.square(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "The assignment function is really quite simple, using `numpy.argmin` to return the\n",
    "index of the smallest row-wise value in the squared distance matrix $S$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diy_kmeans_assign(S):\n",
    "\n",
    "    # Label by column index of smallest value\n",
    "\n",
    "    c = np.argmin(S, axis=1)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find new centers\n",
    "\n",
    "Next we need to find the $k$ new centers by taking the mean of the data points\n",
    "within each assigned cluster. We'll use a list comprehension and `numpy.mean` to simplify the coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diy_kmeans_update_centers(dat, k_labels):\n",
    "\n",
    "    # For each cluster label, find the mean of data points indexed by label\n",
    "    # position for that cluster\n",
    "\n",
    "    new_k_centers = np.array([np.mean(dat[k_labels == k, :], axis=0)\n",
    "                             for k in np.unique(k_labels)])\n",
    "\n",
    "    return new_k_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping criteria\n",
    "\n",
    "Again, one simple function allows us to detect when the algorithm has converged\n",
    "to a solution -- `numpy.array_equiv` checks to see if the elements of two arrays\n",
    "are equivalent. \n",
    "\n",
    "For $k$-means, if the centers stop moving then the data point assignments\n",
    "haven't changed either. We'll use that for our stopping criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diy_kmeans_converged(old_centers, new_centers):\n",
    "\n",
    "    # Returns a Boolean value of equivalence\n",
    "\n",
    "    converged = np.array_equiv(old_centers, new_centers)\n",
    "\n",
    "    return converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling the algorithm\n",
    "\n",
    "Now, we assemble off of the tasks and implement Lloyd's algorithm for $k$-means\n",
    "clustering. The function returns a dictionary of the converged clustering\n",
    "centers and an array of assigned labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diy_kmeans(dat, n_clusters, max_iter=np.inf):\n",
    "\n",
    "    # Initial state and iteration counter\n",
    "    converged = False\n",
    "    i = 0\n",
    "\n",
    "    # Initialize centers\n",
    "    new_centers = diy_kmeans_initialize(dat, n_clusters)\n",
    "\n",
    "    # Repeat until convergence or maximum iterations reached\n",
    "\n",
    "    while (not converged) and (i <= max_iter):\n",
    "\n",
    "        # Update iteration counter\n",
    "        i += 1\n",
    "\n",
    "        # Store copy of prior centers\n",
    "        old_centers = new_centers.copy()\n",
    "\n",
    "        # Get distances to centers as matrix S\n",
    "        S = diy_kmeans_distance(dat, new_centers)\n",
    "\n",
    "        # Assign clusters to matrix C\n",
    "        C = diy_kmeans_assign(S)\n",
    "\n",
    "        # Calculate new centers\n",
    "        new_centers = diy_kmeans_update_centers(dat, C)\n",
    "\n",
    "        # Status update for \"sanity checks\" every 10 iterations\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration:\\t\", i)\n",
    "\n",
    "        # Check stopping criteria\n",
    "        converged = diy_kmeans_converged(old_centers, new_centers)\n",
    "\n",
    "    # Convergence notification\n",
    "    print('Converged in %s iterations.' % i)\n",
    "\n",
    "    # Create dictionary of labelled cluster centers\n",
    "    centers = {k: new_centers[k, :] for k in np.unique(C)}\n",
    "    labels = C\n",
    "\n",
    "    return centers, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
